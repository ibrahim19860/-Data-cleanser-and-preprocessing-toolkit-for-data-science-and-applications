The Data cleaning Toolkit is a well structured and specialized python package which is specifically created to preprocess raw datasets containing various inconsistencies such as missing values, outliers, duplicate data, and inconsistent categorical variables. These inconsistencies which are present in the most of the datasets can majorly impact the performance of the machine learning models, which ultimately leads to biased predictions and lower accuracy. The toolkit automates the process of the data cleaning by applying certain methodologies such as statistical imputation, outlier detection, duplicate removal, categorical encoding, and feature scaling, ensuring that the ambiguous datasets are transformed into a highly structured and well optimized format for various real world machine learning applications.  
To measure and understand the effectiveness and efficiency of the data cleaning toolkit package made using python, the standard raw dataset was taken and subjected to a series of different preprocessing and normalization steps. The missing values present in the raw dataset were handled using the methods mean, median, or mode imputation, depending on the feature type. Outliers or noise were detected within the dataset and was removed using Interquartile Range (IQR) and Z-score techniques. Duplicates entries were identified and fully eliminated to make sure the uniqueness of the dataset. Categorical variables were standardized using one-hot encoding and label encoding, and similarly numerical features were normalized, and standardized to maintain certain level of consistency in the data distribution. The improvements which were achieved in the data quality are clearly summarized in Table 1.
